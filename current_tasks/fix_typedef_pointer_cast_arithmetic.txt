Fix typedef pointer cast arithmetic bug

Bug: When a char* (or other pointer) is cast to a typedef'd pointer type
and then used in pointer arithmetic (subtraction/addition), the compiler
treats the pointed-to type as having size 1 instead of the actual struct size.

Example:
  typedef struct Foo *FooPtr;
  char *endptr = ...;
  FooPtr p = ((FooPtr) endptr) - 1;  // BUG: subtracts 1 byte instead of sizeof(struct Foo)

This is the root cause of 130+ postgres test failures (OID 108544 corruption).
The postgres trigger system uses this pattern in AfterTriggerSaveEvent/afterTriggerAddEvent
to compute offsets within memory chunks.

The bug is in the cast expression type resolution - when a cast produces a
typedef'd pointer type, the pointee type information is lost, causing pointer
arithmetic to use element size 1.

Direct struct pointer casts work fine: ((struct Foo *) endptr) - 1 is correct.
Only typedef aliases trigger the bug: ((FooPtr) endptr) - 1 is wrong.
